import numpy as np
import xlrd
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Dropout


'''

############################### DEFINITIONER #################################


'''



class Layer:
    
    def __init__(self, kernel, bias, activation):
        
        self.kernel = kernel
        self.bias = bias
        self.activation = activation
        #kernel:(input x nNeurons)

    
    def forward(self, input):
        
        #input väntas som en (1 x nInput) np.arr
        
        
        for j in range(len(self.kernel[0])):
            
            #räkna ut neuroners output
            
            res_neuron = 0
            
            for i in range(len(input)):
                
                res_neuron += input[i] * self.kernel[i][j]
            
            res_neuron += self.bias[j]
            
            if self.activation == 'relu':
                
                neuron_output = relu(res_neuron)
            
            elif self.activation == 'sigmoid':
                
                neuron_output = sigmoid(res_neuron)
            
            else:
                
                print('Ogiltig aktiveringsfunktion angiven, välj mellan relu och sigmoid')
                
                break
            
            #ge output som np.ndarray
            
            if j == 0:
                
                output = np.array((neuron_output))
            
            else:
                
                output = np.hstack([output, neuron_output])
            
        return output
        


def relu(input):
    
    return(max(0.0, input))


def sigmoid(input):

    if input >= 0:
        
        return 1/(1 + np.exp(-input))

    else:

        return np.exp(input)/(1 + np.exp(input))


'''

############################### DATALADDNING #################################

'''

red_path = r'PATH_STRUKEN_HÄR'
green_path = r'PATH_STRUKEN_HÄR'
blue_path = r'PATH_STRUKEN_HÄR'
yellow_path = r'PATH_STRUKEN_HÄR'
cyan_path = r'PATH_STRUKEN_HÄR'

def read_data(path):
    #Läser träningsdata från Excel-bok, returnerar tuple med arrayer för design/dep-variabel
    
    xlbk = xlrd.open_workbook(path)
    
    sh = xlbk.sheet_by_index(0)
    
    for i in range(1, sh.ncols):
        
        tlist = []
        
        for j in range(12,17):
            
            tlist.append(sh.cell_value(j,i))
        
        if i == 1:
            
            design = np.array((tlist))
            
            dep = np.array([sh.cell_value(17,i)])
        
        else:
            
            design = np.vstack([design,tlist])
            
            dep = np.vstack([dep, [sh.cell_value(17,i)]])
    
    return(design,dep)
        

design_red = read_data(red_path)[0]
dep_red = read_data(red_path)[1]

design_green = read_data(green_path)[0]
dep_green = read_data(green_path)[1]

design_yellow = read_data(yellow_path)[0]
dep_yellow = read_data(yellow_path)[1]

design_cyan = read_data(cyan_path)[0]
dep_cyan = read_data(cyan_path)[1]

design_blue = read_data(blue_path)[0]
dep_blue = read_data(blue_path)[1]


'''

################################# NW #########################################

'''

def build_network(design, dep):
    #Returnerar nätverksobjekt för given träningsdata, 10-15-10-1
    
    NW = Sequential()
    NW.add(Dense(10, input_dim=5, activation='relu'))
    NW.add(Dropout(0.2))
    NW.add(Dense(15, activation='relu'))
    NW.add(Dropout(0.2))
    NW.add(Dense(10, activation='relu'))
    NW.add(Dense(1, activation='sigmoid'))
    
    NW.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    
    NW.fit(design, dep, epochs=1500, batch_size=30, verbose=1)
    
    '''
    loss = NW.evaluate(design, dep)[0]
    accuracy = NW.evaluate(design, dep)[1]
    
    preds = NW.predict(design)
    
    '''
    return NW

NW_red = build_network(design_red, dep_red)
NW_green = build_network(design_green, dep_green)
NW_yellow = build_network(design_yellow, dep_yellow)
NW_cyan = build_network(design_cyan, dep_cyan)
NW_blue = build_network(design_blue, dep_blue)


#'NW' håller modellen (10-15-10-1). loss, accuracy, preds (nparr) self expl

'''

########################## EXTRAHERA MODELL ##################################

'''

def write_network(path, NW):
    
    c_layer = 0
    
    for i in NW.layers:
        
        if 'dense' in i.name: #Vi vill inte extrahera dropout-lager
        
            kernel = i.get_weights()[0]
            bias = i.get_weights()[1]
            
            path_kernel = path + str(c_layer) + '_kernel.txt'
            path_bias = path + str(c_layer) + '_bias.txt' 
            
            np.savetxt(path_kernel, kernel, delimiter = ',')
            np.savetxt(path_bias, bias, delimiter = ',')    
            
            c_layer +=1 



write_network(r'PATH_STRUKEN_HÄR', NW_red)
write_network(r'PATH_STRUKEN_HÄR', NW_green)
write_network(r'PATH_STRUKEN_HÄR', NW_yellow)
write_network(r'PATH_STRUKEN_HÄR', NW_cyan)
write_network(r'PATH_STRUKEN_HÄR', NW_blue)
